{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SparkTask.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOYh2wzfVfeCY9ElEJVkmnl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samaaMuhamad/spark-task/blob/main/SparkTask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "PGN0dZBccdZ8",
        "outputId": "623a138b-72bf-4715-ea30-e77cd573c68e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to security.\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to security.\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to security.\r0% [1 InRelease gpgv 1,581 B] [Connecting to archive.ubuntu.com (185.125.190.39\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 1,581 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rGet:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [787 kB]\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,990 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,792 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,021 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,281 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,507 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [22.8 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [954 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [988 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,223 kB]\n",
            "Get:25 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:26 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.3 kB]\n",
            "Fetched 16.0 MB in 3s (4,867 kB/s)\n",
            "Reading package lists... Done\n",
            "pagecounts-20160101-000000_parsed.out  spark-2.3.1-bin-hadoop2.7\n",
            "sample_data\t\t\t       spark-2.3.1-bin-hadoop2.7.tgz\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fc913974c90>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://645f9f25eb27:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.1-bin-hadoop2.7\"\n",
        "\n",
        "!ls\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate() \n",
        "spark\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"Learning_Spark\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "\n",
        "#query 1 \n",
        "\n",
        "sc = spark.sparkContext\n",
        "\n",
        "listKamla=[]  #de 3mlaha 3shan a7ot feha el integrs kolha w b3den a7wel el list be paralelize le rdd\n",
        "#w fel akher a3mel union lel rdd da m3 el rdds bto3 query 1 w 5\n",
        "lines = sc.textFile(\"pagecounts-20160101-000000_parsed.out\").persist()   #3shan hafdal ast3melo ta7t fa 3mlto persist\n",
        "\n",
        "\n",
        "print(lines.take(10)) #action\n",
        "res=lines.take(10)\n",
        "res=[\"Query1\"]+res\n",
        "resultQ1=sc.parallelize(res) #action\n",
        "\n",
        "#parallize bt7wel list le rdd 3shan a2dr a3melo save as text file\n",
        "\n",
        "\n",
        "##############################################################\n",
        "\n",
        "#query 2\n",
        "\n",
        "def parseLine(line):\n",
        "    fields = line.split(' ')\n",
        "    pageSize = int(fields[3])\n",
        "    return (pageSize)\n",
        "\n",
        "pagesizes = lines.map(parseLine).persist()  #de transformation\n",
        "\n",
        "print(\"Query 2\")\n",
        "listKamla.append(\"Query2\")\n",
        "#orderedSmallToLarge= pagesizes.takeOrdered(1) \n",
        "minimum=pagesizes.reduce(lambda a,b:min(a,b)) #action\n",
        "print(\"Minimum of page sizes: \",minimum)\n",
        "listKamla.append(minimum)\n",
        "\n",
        "\n",
        "#orderedLargeToSmall= pagesizes.takeOrdered(1, key = lambda x: -x[1])\n",
        "maximum=pagesizes.reduce(lambda a,b:max(a,b)) #action\n",
        "print(\"Maximum of page sizes: \",maximum)\n",
        "listKamla.append(maximum)\n",
        "\n",
        "summation=pagesizes.reduce(lambda a,b:a +b)\n",
        "countData=pagesizes.count()\n",
        "print(\"Average of page sizes: \", summation/countData)        \n",
        "listKamla.append(summation/countData)\n",
        "################################################################\n",
        "\n",
        "#query 3\n",
        "\n",
        "def parseLineTwo(line):\n",
        "  fields = line.split(' ')\n",
        "  pageTitle = fields[1]\n",
        "  projectCode = fields[0]\n",
        "  return (projectCode,pageTitle)\n",
        "\n",
        "def startwith(line):\n",
        "  if(line[1].startswith(\"The\")):\n",
        "    return line\n",
        "def notEnglishProject(line):\n",
        "  if(line[0] != 'en'):\n",
        "    return line\n",
        "\n",
        "\n",
        "print(\"Query 3\")\n",
        "listKamla.append(\"Query3\")\n",
        "\n",
        "pageTitlesAndCodes = lines.map(parseLineTwo) #transformation\n",
        "\n",
        "pagesTitlesStartWithThe=pageTitlesAndCodes.filter(startwith) #transformation\n",
        "\n",
        "print(\"Page titles that start with The : \",pagesTitlesStartWithThe.count()) #action\n",
        "listKamla.append(pagesTitlesStartWithThe.count())\n",
        "\n",
        "\n",
        "notEnglish= pagesTitlesStartWithThe.filter(notEnglishProject)\n",
        "print(\"Page titles that start with The and not english project : \",notEnglish.count())    \n",
        "listKamla.append(notEnglish.count())\n",
        "#####################################################################\n",
        "\n",
        "\n",
        "#query 4\n",
        "\n",
        "listKamla.append(\"Query 4\")\n",
        "def parseLineQuery1(line):\n",
        "  fields = line.split(' ')\n",
        "  pageTitle = fields[1] \n",
        "  return pageTitle\n",
        "\n",
        "def parseTerms(title):\n",
        "  allFields= title.split('_')\n",
        "  return allFields\n",
        "\n",
        "\n",
        "\n",
        "def enterr(line):\n",
        "  for t in line:\n",
        "    termsNew=''.join(filter(str.isalnum, t.lower()))\n",
        "  return termsNew\n",
        "\n",
        "\n",
        "\n",
        "pageTitlesssAll = lines.map(parseLineQuery1)\n",
        "pageTerms=pageTitlesssAll.map(parseTerms)\n",
        "termsNN=pageTerms.map(enterr)\n",
        "\n",
        "print(\"Unique terms in page titles are: \" ,termsNN.take(10))\n",
        "uniq=termsNN.distinct()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Query 4\")\n",
        "\n",
        "\n",
        "print(\"Number of uniue page terms \" , uniq.count())\n",
        "\n",
        "listKamla.append(uniq.count())\n",
        "######################################################\n",
        "\n",
        "#query 5\n",
        "def parseLineQuery(line):\n",
        "  fields = line.split(' ')\n",
        "  pageTitle = ''.join(filter(str.isalnum, fields[1].lower()))  #.lower btkhlleeha small, el kalam ely ablaha da\n",
        "  return (pageTitle)  #by3mel check str.isalnum \n",
        "#isalnum() function, which checks whether a given string contains alphanumeric characters or not by checking each character. \n",
        "#The join() function combines all the characters to return a string.\n",
        "\n",
        "\n",
        "pageTitles = lines.map(parseLineQuery).persist()    #3shan hast3melo ta7t fa 3mlto persist\n",
        "\n",
        "\n",
        "\n",
        "print(\"Query 5\")\n",
        "\n",
        "pageTitlesCounts = pageTitles.map(lambda word: (word, 1)).reduceByKey(lambda a,b:a +b)\n",
        "#pageTitlesCounts.saveAsTextFile(\"titlecountFinalKhaless4\")\n",
        "\n",
        "resultt=pageTitlesCounts.takeOrdered(2, key = lambda x: -x[1]) #take ordered de action Returns the first n elements of the RDD \n",
        "resultt=[\"Query5\"]+resultt\n",
        "print(resultt)\n",
        "resultQ5=sc.parallelize(resultt)  #parallize bt7wel list le rdd 3shan a2dr a3melo save as text file\n",
        "\n",
        "#using either their natural order or a custom comparator\n",
        "#lw 3yzen a3la wa7da bas hanakhly 5 be 1\n",
        "#ana hena b3mel zy query 4 w basheel ay 7aga msh alphanumericc w bakhlehom lowercase\n",
        "listKamla2=sc.parallelize(listKamla)\n",
        "resulttFinal=resultQ1.union(listKamla2)\n",
        "resulttFinal2=resulttFinal.union(resultQ5)\n",
        "\n",
        "resulttFinal2.saveAsTextFile('LastFile')\n",
        "\n",
        "###########################################################################\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "og1PyZsN0jOA",
        "outputId": "33994dd1-b588-4e9c-e1c2-29e1209cb53a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aa 271_a.C 1 4675', 'aa Category:User_th 1 4770', 'aa Chiron_Elias_Krase 1 4694', 'aa Dassault_rafaele 2 9372', 'aa E.Desv 1 4662', 'aa File:Wiktionary-logo-en.png 1 10752', 'aa Indonesian_Wikipedia 1 4679', 'aa Main_Page 5 266946', 'aa Requests_for_new_languages/Wikipedia_Banyumasan 1 4733', 'aa Special:Contributions/203.144.160.245 1 5812']\n",
            "Query 2\n",
            "Minimum of page sizes:  0\n",
            "Maximum of page sizes:  141180155987\n",
            "Average of page sizes:  132239.56957446598\n",
            "Query 3\n",
            "Page titles that start with The :  45020\n",
            "Page titles that start with The and not english project :  10292\n",
            "Unique terms in page titles are:  ['ac', 'th', 'krase', 'rafaele', 'edesv', 'filewiktionarylogoenpng', 'wikipedia', 'page', 'banyumasan', 'specialcontributions203144160245']\n",
            "Query 4\n",
            "Number of uniue page terms  1218892\n",
            "Query 5\n",
            "['Query5', ('', 207), ('water', 127)]\n"
          ]
        }
      ]
    }
  ]
}